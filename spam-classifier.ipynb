{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Classifier using Bayes Theorem\n",
    "This is simple naive bayes classifier, or a classifier using Bayes Theorem to computer probabilities given new data, used to classify messages as either spam or not spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = pd.read_csv(\"spam.csv\")\n",
    "print(dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_spam = 0\n",
    "n_total = 0\n",
    "n_total_spam_words = 0\n",
    "n_total_ham_words = 0\n",
    "\n",
    "# Initializes dictionary mapping words to frequencies\n",
    "# in both spam and not spam (ham) messages\n",
    "word_freq_ham = {}\n",
    "word_freq_spam = {}\n",
    "\n",
    "label, text = (dataframe['v1'], dataframe['v2'])\n",
    "\n",
    "for i in range(len(dataframe['v1'])):\n",
    "    for word in text[i].split():\n",
    "        try:\n",
    "            if label[i] == \"spam\":\n",
    "                word_freq_spam[word] += 1\n",
    "            else:\n",
    "                word_freq_ham[word] += 1\n",
    "        except:\n",
    "            if label[i] == \"spam\":\n",
    "                word_freq_spam[word] = 1\n",
    "            else:\n",
    "                word_freq_ham[word] = 1\n",
    "                \n",
    "        if label[i] == \"spam\":\n",
    "            n_total_spam_words += 1\n",
    "        else:\n",
    "            n_total_ham_words += 1\n",
    "    \n",
    "    if label[i] == \"spam\":\n",
    "        n_spam += 1\n",
    "        \n",
    "    n_total += 1\n",
    "    \n",
    "# Gets prior knowledge of the probability of a given\n",
    "# message being spam and ham\n",
    "spam_prior = n_spam/n_total\n",
    "ham_prior = (n_total - n_spam)/n_total\n",
    "\n",
    "print(spam_prior)\n",
    "print(ham_prior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_spam(text):\n",
    "    spam = 1\n",
    "    ham = 1\n",
    "    \n",
    "    # Finding joint probability for both spam and\n",
    "    # ham for every word\n",
    "    for word in text.split():\n",
    "        \n",
    "        # Get the frequency of the word appearing given that\n",
    "        # the message is spam\n",
    "        if word in word_dist_spam:\n",
    "            freq_in_spam = word_dist_spam[word]\n",
    "        else:\n",
    "            # Applies laplace smoothing, setting frequency to 1\n",
    "            # if the word did not appear in the training data\n",
    "            freq_in_spam = 1\n",
    "            \n",
    "        # Likewise, get the frequency of the word appearing given\n",
    "        # the message is ham\n",
    "        if word in word_dist_ham:\n",
    "            freq_in_ham = word_dist_ham[word]\n",
    "        else:\n",
    "            freq_in_ham = 1\n",
    "            \n",
    "        # Divide frequency by total to get probability\n",
    "        \n",
    "        # P(word|spam)\n",
    "        prob_in_spam = freq_in_spam / n_total_spam_words\n",
    "        \n",
    "        # P(word|ham)\n",
    "        prob_in_ham = freq_in_ham / n_total_ham_words\n",
    "        \n",
    "        # P(word)\n",
    "        prob_in_message = (freq_in_ham + freq_in_spam) / (n_total_ham_words + n_total_spam_words)\n",
    "            \n",
    "        # Computing joint probability for every word\n",
    "        \n",
    "        # Dividing P(word|spam)/P(word)\n",
    "        spam *= prob_in_spam / prob_in_message\n",
    "        \n",
    "        # Dividing P(word|ham)/P(word)\n",
    "        ham *= prob_in_ham / prob_in_message\n",
    "        \n",
    "    # Applying prior knowledge, multiplying by P(spam) and P(ham)\n",
    "    spam *= spam_prior\n",
    "    ham *= ham_prior\n",
    "    \n",
    "    # 1 means spam, 0 means ham\n",
    "    return int(spam > ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(classify_spam(\"Ever wanted to go on an Alaskan Cruise? Call 555-5555 to go for free!\"))\n",
    "print(classify_spam(\"Hey check this cool vid out\"))\n",
    "print(classify_spam(\"Click here to claim your reward\"))\n",
    "print(classify_spam(\"Do you think water is wet?\"))\n",
    "print(classify_spam(\"Hey, I was wondering if we were still planning to meet up today.\"))\n",
    "print(classify_spam(\"Big awards await if you complete this week's challenges!\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
